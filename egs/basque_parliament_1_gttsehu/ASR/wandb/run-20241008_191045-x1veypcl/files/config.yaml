_wandb:
    value:
        cli_version: 0.18.3
        m: []
        python_version: 3.9.12
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.9.12
            "5": 0.18.3
            "8":
                - 5
            "12": 0.18.3
            "13": linux-x86_64
am_scale:
    value: 0
attention_decoder_attention_dim:
    value: 512
attention_decoder_dim:
    value: 512
attention_decoder_feedforward_dim:
    value: 2048
attention_decoder_loss_scale:
    value: 0.8
attention_decoder_num_heads:
    value: 8
attention_decoder_num_layers:
    value: 6
average_period:
    value: 200
base_lr:
    value: 0.045
bpe_model:
    value: /mnt/ahogpu_ldisk2/adriang/icefall/egs/basque_parliament_1_gttsehu/ASR/data/lang_bpe_256/bpe.model
bucketing_sampler:
    value: true
causal:
    value: false
chunk_size:
    value: 16,32,64,-1
cnn_module_kernel:
    value: 31,31,15,15,15,31
concatenate_cuts:
    value: false
context_size:
    value: 2
ctc_loss_scale:
    value: 0.2
decoder_dim:
    value: 512
downsampling_factor:
    value: 1,2,4,8,4,2
drop_last:
    value: true
duration_factor:
    value: 1
enable_musan:
    value: true
enable_spec_aug:
    value: true
encoder_dim:
    value: 192,256,384,512,384,256
encoder_unmasked_dim:
    value: 192,192,256,256,256,192
exp_dir:
    value: zipformer/exp_transducer_False_ctc_True_attdecoder_True_streaming_False
feedforward_dim:
    value: 512,768,1024,1536,1024,768
gap:
    value: 1
inf_check:
    value: false
input_strategy:
    value: PrecomputedFeatures
joiner_dim:
    value: 512
keep_last_k:
    value: 30
left_context_frames:
    value: 64,128,256,-1
lm_scale:
    value: 0.25
lr_batches:
    value: 7500
lr_epochs:
    value: 3.5
manifest_dir:
    value: /mnt/ahogpu_ldisk2/adriang/icefall/egs/basque_parliament_1_gttsehu/ASR/data/fbank
master_port:
    value: 12354
max_duration:
    value: 200
num_buckets:
    value: 30
num_encoder_layers:
    value: 2,2,3,4,3,2
num_epochs:
    value: 30
num_heads:
    value: 4,4,4,8,4,4
num_workers:
    value: 2
on_the_fly_feats:
    value: false
pos_dim:
    value: 48
pos_head_dim:
    value: "4"
print_diagnostics:
    value: false
prune_range:
    value: 5
query_head_dim:
    value: "32"
ref_duration:
    value: 600
return_cuts:
    value: true
save_every_n:
    value: 4000
seed:
    value: 42
shuffle:
    value: true
simple_loss_scale:
    value: 0.5
spec_aug_time_warp_factor:
    value: 80
start_batch:
    value: 0
start_epoch:
    value: 1
tensorboard:
    value: true
use_attention_decoder:
    value: true
use_bf16:
    value: false
use_ctc:
    value: true
use_fp16:
    value: false
use_transducer:
    value: false
value_head_dim:
    value: "12"
world_size:
    value: 3
